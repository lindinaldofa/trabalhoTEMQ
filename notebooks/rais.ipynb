{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook utilizado para criar a base de dados da RAIS com as informações que serão utilizadas.\n",
    "\n",
    "#### Os arquivos da RAIS foram baixados via ftp pelo link: ftp://ftp.mtps.gov.br/pdet/microdados/\n",
    "#### Em seguida, foram extraídos na pasta local E:/Apps/Dados/Rais\n",
    "##### Os arquivos não foram incluídos no projeto por serem muito grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as colunas que serão utilizadas.\n",
    "columns = ['Município', 'CNAE 2.0 Classe', 'Vínculo Ativo 31/12', 'Vl Remun Dezembro Nom']\n",
    "# Lista de sufixos dos arquivos.\n",
    "arqs = ['CENTRO_OESTE','MG_ES_RJ','NI','NORDESTE','NORTE','SP','SUL']\n",
    "# Ano da Rais que será tratado.\n",
    "ano = '2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando  CENTRO_OESTE\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "3 - Concluída.\n",
      "Finalizado  CENTRO_OESTE\n",
      "__________________\n",
      "Iniciando  MG_ES_RJ\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "3 - Concluída.\n",
      "4 - Concluída.\n",
      "5 - Concluída.\n",
      "6 - Concluída.\n",
      "7 - Concluída.\n",
      "8 - Concluída.\n",
      "Finalizado  MG_ES_RJ\n",
      "__________________\n",
      "Iniciando  NI\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "Finalizado  NI\n",
      "__________________\n",
      "Iniciando  NORDESTE\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "3 - Concluída.\n",
      "4 - Concluída.\n",
      "5 - Concluída.\n",
      "6 - Concluída.\n",
      "Finalizado  NORDESTE\n",
      "__________________\n",
      "Iniciando  NORTE\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "Finalizado  NORTE\n",
      "__________________\n",
      "Iniciando  SP\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "3 - Concluída.\n",
      "4 - Concluída.\n",
      "5 - Concluída.\n",
      "6 - Concluída.\n",
      "7 - Concluída.\n",
      "8 - Concluída.\n",
      "9 - Concluída.\n",
      "10 - Concluída.\n",
      "11 - Concluída.\n",
      "Finalizado  SP\n",
      "__________________\n",
      "Iniciando  SUL\n",
      "Tratando partes do arquivo:\n",
      "0 - Concluída.\n",
      "1 - Concluída.\n",
      "2 - Concluída.\n",
      "3 - Concluída.\n",
      "4 - Concluída.\n",
      "5 - Concluída.\n",
      "6 - Concluída.\n",
      "7 - Concluída.\n",
      "Finalizado  SUL\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "# Criando a base de dados da RAIS\n",
    "\n",
    "# Cria o DataFrame que será utilizado no final.\n",
    "df_final = pd.DataFrame()\n",
    "# Cria uma lista para receber os locais dos arquivos temporários.\n",
    "list_files = []\n",
    "\n",
    "for a in arqs:\n",
    "    print('Iniciando', a)\n",
    "    path = 'E:/Apps/Dados/Rais/{0}/RAIS_VINC_PUB_{1}.txt'.format(ano,a)\n",
    "    \n",
    "    # Como os arquivos são muito grandes eles serão tratados em partes, sendo divididos a cada 2 milhões de linhas.\n",
    "    \n",
    "    print('Tratando partes do arquivo:')\n",
    "    list_chunks = []\n",
    "    for i, chunk in enumerate(pd.read_csv(path, delimiter=';', encoding='latin-1', usecols=columns, low_memory=False, chunksize=2000000)):\n",
    "        # Tornando o valor de 'Vl Remun Dezembro Nom' em um float.\n",
    "        chunk['Vl Remun Dezembro Nom'] = chunk['Vl Remun Dezembro Nom'].apply(lambda x: x.replace(',','.')).astype('float')\n",
    "        # Adicionando um contator para os vínculos ativos em 31/12.\n",
    "        rais_at = chunk[chunk['Vínculo Ativo 31/12'] == 1]\n",
    "        # Agrupando por atividade econômica e município.\n",
    "        chunk_res = rais_at.groupby(by=['CNAE 2.0 Classe', 'Município'], as_index=False).sum()\n",
    "        # Renomeando as colunas.\n",
    "        chunk_res.rename(columns = {'CNAE 2.0 Classe': 'ID CNAE', 'Vínculo Ativo 31/12': 'Número Empregos', 'Vl Remun Dezembro Nom': 'Massa Salarial'}, inplace=True)\n",
    "        list_chunks.append(chunk_res)\n",
    "        print('{0} - Concluída.'.format(i))\n",
    "    # Unifica as partes tratadas do arquivo em um único DataFrame e salva um arquivo temporário em pickle.\n",
    "    df = pd.concat(list_chunks)\n",
    "    temp_file = 'E:/Apps/Dados/Rais/{0}/Tratados/tratado{0}{1}.pkl'.format(ano,a)\n",
    "    df.to_pickle(temp_file)\n",
    "    list_files.append(temp_file)\n",
    "    print('Finalizado', a)\n",
    "    print('__________________')\n",
    "\n",
    "# Para finalizar é feita a concatenação no df_final e ele é salvo.\n",
    "df_final = pd.concat([pd.read_pickle(f) for f in list_files])\n",
    "df_final.to_pickle('../assets/rais{0}.pkl'.format(ano),  compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
